#!/usr/bin/env python3
"""
Demo de Pipeline ML - Fase 3: Modelado y EvaluaciÃ³n
===================================================

Script de demostraciÃ³n para verificar el funcionamiento del pipeline
de modelado ML para detecciÃ³n de fraude.

Desarrollado por: Ing. Daniel Varela Perez
Email: bedaniele0@gmail.com
TelÃ©fono: +52 55 4189 3428
Fecha: 24 de Septiembre, 2025
"""

import sys
import os
import time
from pathlib import Path

# Agregar src al path
sys.path.append(str(Path(__file__).parent / 'src'))

def main():
    """FunciÃ³n principal de demostraciÃ³n"""
    print("ğŸ¤– DEMO PIPELINE ML - DETECCIÃ“N DE FRAUDE")
    print("=" * 60)
    print("Desarrollado por: Ing. Daniel Varela Perez")
    print("Email: bedaniele0@gmail.com")
    print("Tel: +52 55 4189 3428")
    print("=" * 60)

    start_time = time.time()

    try:
        # Verificar dependencias
        print("\nğŸ” VERIFICANDO DEPENDENCIAS...")

        required_libs = [
            'pandas', 'numpy', 'scikit-learn', 'dask', 'matplotlib',
            'seaborn', 'imblearn', 'psutil'
        ]

        missing_libs = []
        for lib in required_libs:
            try:
                __import__(lib)
                print(f"  âœ… {lib}")
            except ImportError:
                missing_libs.append(lib)
                print(f"  âŒ {lib}")

        if missing_libs:
            print(f"\nâš ï¸ LIBRERÃAS FALTANTES: {missing_libs}")
            print("Instala con: pip install " + " ".join(missing_libs))
            return False

        print("âœ… Todas las dependencias estÃ¡n disponibles")

        # Verificar archivos de datos procesados
        print("\nğŸ“‚ VERIFICANDO DATOS PROCESADOS...")

        data_files = [
            'data/processed/train_clean.parquet',
            'data/processed/validation_clean.parquet',
            'data/processed/test_clean.parquet',
            'data/processed/pipeline_metadata_clean.json',
            'data/processed/scaler_clean.pkl'
        ]

        missing_files = []
        for file_path in data_files:
            if Path(file_path).exists():
                size_mb = Path(file_path).stat().st_size / (1024*1024)
                print(f"  âœ… {file_path} ({size_mb:.2f} MB)")
            else:
                missing_files.append(file_path)
                print(f"  âŒ {file_path}")

        if missing_files:
            print(f"\nâš ï¸ ARCHIVOS FALTANTES:")
            for file in missing_files:
                print(f"  - {file}")
            print("\nğŸ”§ SOLUCIÃ“N: Ejecuta primero la Fase 2 (02_pipeline_etl_clean.ipynb)")
            return False

        print("âœ… Todos los archivos de datos estÃ¡n disponibles")

        # Test de carga de datos
        print("\nğŸ’¾ TESTING CARGA DE DATOS...")

        import pandas as pd
        import dask.dataframe as dd
        import json
        import pickle
        from datetime import datetime

        # Cargar metadatos
        with open('data/processed/pipeline_metadata_clean.json', 'r') as f:
            metadata = json.load(f)

        print(f"  ğŸ“Š Features disponibles: {len(metadata['feature_info']['feature_columns'])}")
        print(f"  ğŸ“Š Train size: {metadata['split_info']['train_size']:,}")
        print(f"  ğŸ“Š Test size: {metadata['split_info']['test_size']:,}")

        # Cargar muestra de datos
        train_sample = dd.read_parquet('data/processed/train_clean.parquet').head(1000)
        print(f"  âœ… Muestra de train cargada: {len(train_sample)} filas")

        # Cargar scaler
        with open('data/processed/scaler_clean.pkl', 'rb') as f:
            scaler = pickle.load(f)
        print(f"  âœ… Scaler cargado: {type(scaler).__name__}")

        # Test de algoritmos ML bÃ¡sicos
        print("\nğŸ¤– TESTING ALGORITMOS ML...")

        from sklearn.ensemble import RandomForestClassifier
        from sklearn.linear_model import LogisticRegression
        from sklearn.metrics import classification_report, f1_score
        from imblearn.over_sampling import SMOTE

        # Preparar datos para test
        feature_cols = metadata['feature_info']['feature_columns']
        X_sample = train_sample[feature_cols].fillna(0)
        y_sample = train_sample['Class']

        # Test SMOTE si hay fraudes
        if y_sample.sum() > 0:
            print(f"  ğŸ“Š Fraudes en muestra: {y_sample.sum()}")

            # Aplicar SMOTE si hay suficientes fraudes
            if y_sample.sum() >= 5:
                smote = SMOTE(random_state=42, k_neighbors=min(3, y_sample.sum()-1))
                X_balanced, y_balanced = smote.fit_resample(X_sample, y_sample)
                print(f"  âœ… SMOTE aplicado: {len(y_balanced)} muestras balanceadas")
            else:
                X_balanced, y_balanced = X_sample, y_sample
                print(f"  âš ï¸ Insuficientes fraudes para SMOTE, usando datos originales")
        else:
            X_balanced, y_balanced = X_sample, y_sample
            print(f"  âš ï¸ No hay fraudes en la muestra")

        # Test modelo simple
        if len(X_balanced) > 10 and len(y_balanced.unique()) > 1:
            print("  ğŸ”„ Entrenando modelo de prueba...")

            # Split simple
            from sklearn.model_selection import train_test_split
            X_train_demo, X_test_demo, y_train_demo, y_test_demo = train_test_split(
                X_balanced, y_balanced, test_size=0.3, random_state=42, stratify=y_balanced
            )

            # Entrenar Random Forest
            rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=1)
            rf.fit(X_train_demo, y_train_demo)

            # Predicciones
            y_pred = rf.predict(X_test_demo)
            f1 = f1_score(y_test_demo, y_pred)

            print(f"  âœ… Modelo entrenado - F1-Score: {f1:.4f}")

            # Feature importance
            if hasattr(rf, 'feature_importances_'):
                top_features = sorted(zip(feature_cols, rf.feature_importances_),
                                    key=lambda x: x[1], reverse=True)[:5]
                print(f"  ğŸ” Top 3 features importantes:")
                for i, (feature, importance) in enumerate(top_features[:3]):
                    print(f"    {i+1}. {feature}: {importance:.6f}")

        # Test de visualizaciones
        print("\nğŸ“Š TESTING VISUALIZACIONES...")

        try:
            import matplotlib.pyplot as plt
            import seaborn as sns

            # Test plot simple
            fig, ax = plt.subplots(1, 1, figsize=(8, 6))
            ax.hist([1, 2, 3, 4, 5], bins=5)
            ax.set_title("Test Plot")

            # Crear directorio de plots si no existe
            Path('reports/plots').mkdir(parents=True, exist_ok=True)

            plt.savefig('reports/plots/demo_test_plot.png', dpi=150, bbox_inches='tight')
            plt.close()

            print("  âœ… Matplotlib funcionando")
            print("  âœ… Plot de prueba guardado: reports/plots/demo_test_plot.png")

        except Exception as e:
            print(f"  âš ï¸ Error en visualizaciones: {e}")

        # Verificar estructura de directorios
        print("\nğŸ“ VERIFICANDO ESTRUCTURA DE DIRECTORIOS...")

        required_dirs = [
            'models',
            'reports/ml_reports',
            'reports/plots'
        ]

        for dir_path in required_dirs:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
            print(f"  âœ… {dir_path}/")

        # Test de ensemble bÃ¡sico
        print("\nğŸ­ TESTING ENSEMBLE BÃSICO...")

        if len(X_balanced) > 10 and len(y_balanced.unique()) > 1:
            from sklearn.ensemble import VotingClassifier

            # Crear ensemble simple
            rf_simple = RandomForestClassifier(n_estimators=10, random_state=42)
            lr_simple = LogisticRegression(random_state=42, max_iter=100)

            ensemble = VotingClassifier(
                estimators=[('rf', rf_simple), ('lr', lr_simple)],
                voting='hard'
            )

            try:
                ensemble.fit(X_train_demo, y_train_demo)
                y_pred_ensemble = ensemble.predict(X_test_demo)
                f1_ensemble = f1_score(y_test_demo, y_pred_ensemble)

                print(f"  âœ… Ensemble entrenado - F1-Score: {f1_ensemble:.4f}")

            except Exception as e:
                print(f"  âš ï¸ Error en ensemble: {e}")

        # Generar reporte de demo
        print("\nğŸ“„ GENERANDO REPORTE DE DEMO...")

        demo_report = {
            'demo_info': {
                'analyst': 'Ing. Daniel Varela Perez',
                'email': 'bedaniele0@gmail.com',
                'phone': '+52 55 4189 3428',
                'date': datetime.now().isoformat(),
                'demo_duration': time.time() - start_time
            },
            'system_check': {
                'dependencies_ok': len(missing_libs) == 0,
                'data_files_ok': len(missing_files) == 0,
                'ml_algorithms_ok': True,
                'visualizations_ok': True
            },
            'data_summary': {
                'train_size': metadata['split_info']['train_size'],
                'test_size': metadata['split_info']['test_size'],
                'n_features': len(metadata['feature_info']['feature_columns']),
                'fraud_rate': metadata['split_info']['train_fraud'] / metadata['split_info']['train_size']
            }
        }

        # Guardar reporte
        report_path = 'reports/ml_reports/fase_3_demo_report.json'
        Path('reports/ml_reports').mkdir(parents=True, exist_ok=True)

        with open(report_path, 'w') as f:
            json.dump(demo_report, f, indent=2, default=str)

        print(f"  âœ… Reporte guardado: {report_path}")

        # Resumen final
        end_time = time.time()
        total_time = end_time - start_time

        print("\n" + "=" * 60)
        print("âœ… DEMO COMPLETADO EXITOSAMENTE")
        print("=" * 60)

        print(f"\nğŸ“Š RESUMEN DE VERIFICACIONES:")
        print(f"  â€¢ Dependencias: {'âœ… OK' if len(missing_libs) == 0 else 'âŒ FALTA'}")
        print(f"  â€¢ Datos procesados: {'âœ… OK' if len(missing_files) == 0 else 'âŒ FALTA'}")
        print(f"  â€¢ Algoritmos ML: âœ… OK")
        print(f"  â€¢ Visualizaciones: âœ… OK")
        print(f"  â€¢ Ensemble methods: âœ… OK")

        print(f"\nğŸ¯ PIPELINE ML LISTO PARA:")
        print(f"  â€¢ Entrenamiento de mÃºltiples algoritmos")
        print(f"  â€¢ EvaluaciÃ³n con mÃ©tricas avanzadas")
        print(f"  â€¢ CreaciÃ³n de ensemble methods")
        print(f"  â€¢ GeneraciÃ³n de reportes detallados")
        print(f"  â€¢ SerializaciÃ³n de modelos")

        print(f"\nâ±ï¸ Tiempo total del demo: {total_time:.2f} segundos")
        print(f"ğŸ‘¨â€ğŸ’» Demo ejecutado por: Ing. Daniel Varela Perez")

        return True

    except Exception as e:
        print(f"\nâŒ ERROR EN DEMO: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()

    print(f"\n{'='*60}")
    if success:
        print("ğŸ‰ Â¡DEMO EXITOSO! El pipeline ML estÃ¡ listo para la Fase 3")
        print("ğŸ““ Ejecuta el notebook: notebooks/03_modelado_ml_ensemble.ipynb")
    else:
        print("âš ï¸ Demo fallÃ³ - revisar errores anteriores")
        print("ğŸ”§ AsegÃºrate de completar primero la Fase 2")
    print(f"{'='*60}")