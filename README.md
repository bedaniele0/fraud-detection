# ğŸ’³ Sistema Inteligente de DetecciÃ³n de Fraude Financiero

**Autor:** Ing. Daniel Varela PÃ©rez
ğŸ“§ bedaniele0@gmail.com | ğŸ“± +52 55 4189 3428
**MetodologÃ­a:** DVP-PRO (Data Science Professional Framework)

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.25+-red.svg)](https://streamlit.io)
[![Tests](https://img.shields.io/badge/Tests-34%2F34-success.svg)](#testing)
[![ROC-AUC](https://img.shields.io/badge/ROC--AUC-95.28%25-brightgreen.svg)](#mÃ©tricas-del-modelo)
[![Status](https://img.shields.io/badge/Status-Portfolio%20Demo-success.svg)](#)

---

## ğŸ“‹ Tabla de Contenidos

- [Objetivo General](#-objetivo-general)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [MÃ©tricas del Modelo](#-mÃ©tricas-del-modelo)
- [Arquitectura del Sistema](#ï¸-arquitectura-del-sistema)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [GuÃ­a de Uso](#-guÃ­a-de-uso)
- [Testing](#-testing)
- [DocumentaciÃ³n DVP-PRO](#-documentaciÃ³n-dvp-pro)
- [Stack TecnolÃ³gico](#-stack-tecnolÃ³gico)
- [Roadmap](#-roadmap)
- [Contacto](#-contacto)

---

## ğŸ¯ Objetivo General

Sistema de detecciÃ³n de fraude financiero en formato portafolio, implementado con **metodologÃ­a DVP-PRO**, que incluye:

- âœ… **Pipeline ML reproducible** con Random Forest optimizado
- âœ… **API REST** con autenticaciÃ³n JWT para predicciones en tiempo real
- âœ… **Dashboard interactivo** para anÃ¡lisis y visualizaciÃ³n
- âœ… **Suite completa de tests** (34/34 pasando)
- âœ… **Monitoreo (opcional)** con Prometheus/Grafana
- âœ… **Docker (opcional)** para entorno reproducible

**Valor de Negocio:** ReducciÃ³n de fraude con 95.28% ROC-AUC y 93.62% precisiÃ³n, minimizando falsos positivos.

---

## âœ¨ CaracterÃ­sticas Principales

### ğŸ¤– Machine Learning
- **Modelo:** Random Forest Classifier optimizado para datos desbalanceados
- **TÃ©cnicas:** SMOTE para balanceo de clases, optimizaciÃ³n de threshold
- **Versionado:** Artefactos del modelo guardados con metadata en `models/`
- **Threshold ajustable:** Configurable segÃºn estrategia de negocio (default: 0.300)

### ğŸ› ï¸ Pipeline MLOps
- **Entrenamiento:** Script automatizado con validaciÃ³n cruzada
- **EvaluaciÃ³n:** MÃ©tricas comprehensivas en test set
- **Predicciones:** Batch predictions con exportaciÃ³n a CSV
- **Monitoreo:** DetecciÃ³n de data drift y model performance

### ğŸŒ API REST
- **Framework:** FastAPI con Swagger docs auto-generados
- **AutenticaciÃ³n:** JWT tokens para seguridad
- **Endpoints:**
  - `POST /api/v1/predict` â€” PredicciÃ³n individual
  - `POST /api/v1/predict/batch` â€” Predicciones batch (â‰¤1000)
  - `GET /api/v1/model/info` â€” InformaciÃ³n del modelo
  - `PUT /api/v1/model/threshold` â€” Actualizar threshold
  - `GET /api/v1/metrics` â€” MÃ©tricas del modelo

### ğŸ“Š Dashboard Streamlit
- **MÃ³dulo 1:** PredicciÃ³n individual con visualizaciÃ³n de probabilidades
- **MÃ³dulo 2:** AnÃ¡lisis batch con carga de archivos CSV/Parquet
- **MÃ³dulo 3:** MÃ©tricas en tiempo real y acumuladas
- **MÃ³dulo 4:** Visualizaciones interactivas con Plotly

### ğŸ§ª Testing Comprehensivo
- **34 tests unitarios y de integraciÃ³n**
- **Cobertura:** API endpoints, data pipeline, model inference
- **Framework:** pytest con fixtures y mocking
- **CI/CD Ready:** ConfiguraciÃ³n para GitHub Actions

### ğŸ“ˆ Monitoreo y Observabilidad
- **Prometheus:** MÃ©tricas de sistema y modelo
- **Grafana:** Dashboards de visualizaciÃ³n
- **Alerting:** ConfiguraciÃ³n de alertas bÃ¡sicas
- **Logging:** Structured logging con niveles configurables

---

## ğŸ“Š MÃ©tricas del Modelo

### Resultados en Test Set (EvaluaciÃ³n Final)

| MÃ©trica | Valor | InterpretaciÃ³n |
|---------|-------|----------------|
| **Precision** | **93.62%** | De cada 100 transacciones marcadas como fraude, 94 son realmente fraude |
| **Recall** | **72.13%** | El modelo detecta 72 de cada 100 fraudes reales |
| **F1-Score** | **81.48%** | Balance Ã³ptimo entre precisiÃ³n y recall |
| **Accuracy** | **99.96%** | Exactitud global del modelo |
| **ROC-AUC** | **95.28%** | Excelente capacidad discriminativa |
| **Threshold Ã“ptimo** | **0.300** | Optimizado para maximizar F1-Score con Ã©nfasis en recall |

**MÃ©tricas en Validation Set (Training):**
- Precision: 93.62% | Recall: 72.13% | F1: 81.48% | ROC-AUC: 95.28%

**GeneralizaciÃ³n:** El modelo mantiene mÃ©tricas estables entre validation y test, indicando **buena capacidad de generalizaciÃ³n** sin overfitting âœ…

### AnÃ¡lisis de Performance

**Fortalezas:**
- âœ… ROC-AUC de 95.28% indica excelente separaciÃ³n entre clases
- âœ… Precision de 93.62% minimiza falsos positivos (Ãºtil en escenarios reales)
- âœ… F1-Score balanceado para casos de uso reales
- âœ… Modelo generaliza bien (mÃ©tricas estables)

**Trade-offs:**
- Threshold ajustable permite priorizar precision vs recall segÃºn estrategia de negocio
- Modelo optimizado para minimizar costos de falsos positivos

---

## ğŸ’° ROI Demo (con supuestos explÃ­citos)

**Supuestos conservadores:**
- Volumen: 120M transacciones/aÃ±o
- Tasa de fraude: 0.20% (240,000 fraudes/aÃ±o)
- Costo promedio por fraude: $150 USD
- Precision: 93.62% | Recall: 72.13%
- Costo por falsa alerta (revisiÃ³n): $2 USD

**EstimaciÃ³n rÃ¡pida:**
```
TP â‰ˆ 173,115 fraudes detectados/aÃ±o
FP â‰ˆ 11,803 alertas falsas/aÃ±o
Ahorro potencial â‰ˆ $25.9M/aÃ±o
Ahorro conservador (30% captura operativa) â‰ˆ $7.8M/aÃ±o
```

> EstimaciÃ³n de demo basada en mÃ©tricas reales del modelo; en producciÃ³n depende de procesos y capacidad operativa.

## âš™ï¸ Arquitectura del Sistema

### Estructura del Proyecto (DVP-PRO)

```
fraud_detection/
â”œâ”€â”€ api/                          # API REST (FastAPI)
â”‚   â”œâ”€â”€ main.py                   # Endpoints principales
â”‚   â”œâ”€â”€ auth.py                   # AutenticaciÃ³n JWT
â”‚   â””â”€â”€ routers/                  # Routers modulares
â”œâ”€â”€ dashboard/                    # Dashboard interactivo (Streamlit)
â”‚   â””â”€â”€ fraud_detection_dashboard.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                   # ML Pipeline
â”‚   â”‚   â”œâ”€â”€ train_fraud.py        # Entrenamiento del modelo
â”‚   â”‚   â”œâ”€â”€ evaluate.py           # EvaluaciÃ³n en test set
â”‚   â”‚   â””â”€â”€ predict.py            # Predicciones batch
â”‚   â”œâ”€â”€ monitoring/               # Monitoreo y alertas
â”‚   â”‚   â”œâ”€â”€ drift_detection.py    # DetecciÃ³n de data drift
â”‚   â”‚   â””â”€â”€ monitoring_run.py     # Script de monitoreo
â”‚   â”œâ”€â”€ data/                     # Data processing
â”‚   â””â”€â”€ utils/                    # Utilidades
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Datos originales (no versionados)
â”‚   â””â”€â”€ processed/                # Datos procesados (Parquet)
â”‚       â”œâ”€â”€ train_clean.parquet/
â”‚       â”œâ”€â”€ validation_clean.parquet/
â”‚       â””â”€â”€ test_clean.parquet/
â”œâ”€â”€ models/                       # Modelos entrenados
â”‚   â”œâ”€â”€ improved_recall_threshold_model.pkl
â”‚   â”œâ”€â”€ simple_fraud_model.pkl
â”‚   â””â”€â”€ threshold_config.json
â”œâ”€â”€ tests/                        # Suite de tests
â”‚   â”œâ”€â”€ test_api.py               # Tests de API (30 tests)
â”‚   â”œâ”€â”€ test_data_pipeline.py     # Tests de datos (3 tests)
â”‚   â””â”€â”€ test_model_inference.py   # Tests de modelo (2 tests)
â”œâ”€â”€ docs/                         # DocumentaciÃ³n DVP-PRO
â”‚   â”œâ”€â”€ F0_problem_statement.md   # Fase 0: DefiniciÃ³n del problema
â”‚   â”œâ”€â”€ F1_setup.md               # Fase 1: Setup del proyecto
â”‚   â”œâ”€â”€ F2_architecture.md        # Fase 2: Arquitectura
â”‚   â”œâ”€â”€ F3_eda.md                 # Fase 3: EDA
â”‚   â”œâ”€â”€ F4_feature_engineering.md # Fase 4: Feature Engineering
â”‚   â”œâ”€â”€ F5_modeling.md            # Fase 5: Modelado
â”‚   â”œâ”€â”€ F6_evaluation.md          # Fase 6: EvaluaciÃ³n
â”‚   â””â”€â”€ F9_closure.md             # Fase 9: Cierre
â”œâ”€â”€ notebooks/                    # Jupyter notebooks para anÃ¡lisis
â”œâ”€â”€ reports/                      # Reportes y resultados
â”‚   â””â”€â”€ predictions/              # Predicciones generadas
â”œâ”€â”€ config/                       # Archivos de configuraciÃ³n
â”œâ”€â”€ docker-compose.monitoring.yml # Stack de monitoreo
â”œâ”€â”€ Dockerfile                    # ContainerizaciÃ³n
â”œâ”€â”€ requirements.txt              # Dependencias
â”œâ”€â”€ setup.py                      # InstalaciÃ³n del paquete
â”œâ”€â”€ train_model.sh               # Script de entrenamiento
â””â”€â”€ README.md                     # Este archivo
```

### Diagrama de Flujo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data       â”‚
â”‚  (Parquet)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Processing â”‚
â”‚ & Validation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Eng.    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Train/Val   â”‚
â”‚ + SMOTE         â”‚      â”‚  Split       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Random Forestâ”‚
                         â”‚ Training     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Threshold    â”‚
                         â”‚ Optimization â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                      â”‚                      â”‚
         â–¼                      â–¼                      â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   FastAPI   â”‚      â”‚  Streamlit   â”‚      â”‚  Monitoring  â”‚
  â”‚   :8000     â”‚      â”‚   :8501      â”‚      â”‚ Prom/Grafana â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- Python 3.10 o superior
- pip (gestor de paquetes de Python)
- Git

### OpciÃ³n 1: InstalaciÃ³n EstÃ¡ndar

```bash
# 1. Clonar el repositorio
git clone https://github.com/tu-usuario/fraud_detection.git
cd fraud_detection

# 2. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 3. Instalar dependencias
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt

# 4. Instalar el paquete (para comandos CLI)
pip install -e .
```

### OpciÃ³n 2: InstalaciÃ³n con Docker

```bash
# 1. Construir imagen
docker build -t fraud-detection .

# 2. Ejecutar contenedor
docker run -p 8000:8000 fraud-detection
```

### VerificaciÃ³n de InstalaciÃ³n

```bash
# Ejecutar tests
pytest -v

# Resultado esperado: 34/34 passed âœ…
```

---

## ğŸ“– GuÃ­a de Uso

### 1ï¸âƒ£ Entrenar el Modelo

**OpciÃ³n A: Script automÃ¡tico (recomendado)**

```bash
./train_model.sh
```

**OpciÃ³n B: Python directo**

```bash
python3 src/models/train_fraud.py \
    --train-path data/processed/train_clean.parquet/part.0.parquet \
    --val-path data/processed/validation_clean.parquet
```

**Output esperado:**
```
ğŸš€ Entrenando modelo de detecciÃ³n de fraude...
âœ… Modelo entrenado y artefactos guardados
   â€¢ Modelo: models/improved_recall_threshold_model.pkl
   â€¢ Threshold Ã³ptimo: 0.300
   â€¢ MÃ©tricas val: {'precision': 0.9362, 'recall': 0.7213, ...}
```

### 2ï¸âƒ£ Evaluar el Modelo

```bash
python3 src/models/evaluate.py \
    --test-path data/processed/test_clean.parquet
```

### 3ï¸âƒ£ Hacer Predicciones Batch

```bash
python3 src/models/predict.py \
    --input-path data/processed/test_clean.parquet \
    --output-path reports/predictions/predicciones.csv
```

### 4ï¸âƒ£ Lanzar API REST

```bash
# OpciÃ³n 1: Uvicorn directo
python3 -m uvicorn api.main:app --reload

# OpciÃ³n 2: Con configuraciÃ³n personalizada
python3 -m uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

**Acceder a la documentaciÃ³n:**
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

**Ejemplo completo de uso de la API:**

```bash
# 1. Obtener token de autenticaciÃ³n
curl -X POST "http://localhost:8000/token" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "username=admin&password=admin123"

# Response:
# {"access_token":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...","token_type":"bearer"}

# 2. Hacer predicciÃ³n individual (usar el token obtenido)
curl -X POST "http://localhost:8000/api/v1/predict" \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..." \
  -H "Content-Type: application/json" \
  -d '{
    "Time": 120,
    "V1": -1.5,
    "V2": 0.8,
    "V3": 1.2,
    "V4": -0.5,
    "V5": 0.3,
    "V6": -0.7,
    "V7": 0.9,
    "V8": -0.2,
    "V9": 0.6,
    "V10": -1.1,
    "V11": 0.4,
    "V12": -0.8,
    "V13": 0.1,
    "V14": -0.3,
    "V15": 0.7,
    "V16": -0.4,
    "V17": 0.5,
    "V18": -0.6,
    "V19": 0.2,
    "V20": -0.9,
    "V21": 0.8,
    "V22": -0.1,
    "V23": 0.4,
    "V24": -0.5,
    "V25": 0.6,
    "V26": -0.7,
    "V27": 0.3,
    "V28": -0.2,
    "Amount": 150.0
  }'
```

**Response:**
```json
{
  "fraud_probability": 0.12,
  "is_fraud": false,
  "threshold": 0.30,
  "model_version": "1.0.0",
  "timestamp": "2024-12-25T22:45:00.123456"
}
```

**InterpretaciÃ³n:**
- **Probabilidad de fraude:** 12% (bajo riesgo)
- **DecisiÃ³n:** NO es fraude (probabilidad < threshold 0.30)
- **RecomendaciÃ³n:** Aprobar transacciÃ³n automÃ¡ticamente

### 5ï¸âƒ£ Lanzar Dashboard Streamlit

```bash
python3 -m streamlit run dashboard/fraud_detection_dashboard.py
```

**Acceder al dashboard:**
- URL: http://localhost:8501

**Funcionalidades disponibles:**
- ğŸ” PredicciÃ³n individual con visualizaciÃ³n de probabilidades
- ğŸ“‚ AnÃ¡lisis batch (carga de CSV/Parquet)
- ğŸ“ˆ MÃ©tricas en tiempo real
- ğŸ“Š Visualizaciones interactivas

### 6ï¸âƒ£ Monitoreo (Opcional)

```bash
# Levantar stack de monitoreo (Prometheus + Grafana)
docker-compose -f docker-compose.monitoring.yml up -d

# Acceder a:
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3000 (admin/admin)
```

---

## ğŸ§ª Testing

### Ejecutar Suite Completa

```bash
# Tests con output detallado
pytest -v

# Tests con cobertura
pytest --cov=src --cov=api --cov=dashboard --cov-report=html

# Abrir reporte de cobertura
open htmlcov/index.html
```

### DistribuciÃ³n de Tests

| MÃ³dulo | Tests | DescripciÃ³n |
|--------|-------|-------------|
| `test_api.py` | 29 | Tests de endpoints, autenticaciÃ³n, validaciÃ³n |
| `test_data_pipeline.py` | 3 | Tests de calidad y procesamiento de datos |
| `test_model_inference.py` | 2 | Tests de carga y predicciÃ³n del modelo |
| **Total** | **34** | **Cobertura 19%** |

### Tests EspecÃ­ficos

```bash
# Solo tests de API
pytest tests/test_api.py -v

# Solo tests de modelo
pytest tests/test_model_inference.py -v

# Tests con marca especÃ­fica
pytest -m "integration" -v
```

---

## ğŸ“š DocumentaciÃ³n DVP-PRO

Este proyecto sigue la **metodologÃ­a DVP-PRO** (Data Science Professional Framework) con documentaciÃ³n completa en cada fase:

### DocumentaciÃ³n por Fase

| Fase | Documento | DescripciÃ³n |
|------|-----------|-------------|
| **F0** | [Problem Statement](docs/F0_problem_statement.md) | DefiniciÃ³n del problema de negocio |
| **F1** | [Setup](docs/F1_setup.md) | ConfiguraciÃ³n del entorno |
| **F2** | [Architecture](docs/F2_architecture.md) | DiseÃ±o arquitectÃ³nico |
| **F3** | [EDA](docs/F3_eda.md) | AnÃ¡lisis exploratorio de datos |
| **F4** | [Feature Engineering](docs/F4_feature_engineering.md) | IngenierÃ­a de features |
| **F5** | [Modeling](docs/F5_modeling.md) | Desarrollo del modelo |
| **F6** | [Evaluation](docs/F6_evaluation.md) | EvaluaciÃ³n y validaciÃ³n |
| **F7** | Ops (opcional) | Docker/monitoreo si se requiere |
| **F8** | Observabilidad (opcional) | MÃ©tricas y alertas si se requiere |
| **F9** | [Closure](docs/F9_closure.md) | Cierre y lecciones aprendidas |

### DocumentaciÃ³n Adicional

- [Inicio RÃ¡pido](INICIO_RAPIDO.md) - GuÃ­a de 5 minutos
- [Instrucciones de Setup](INSTRUCCIONES_SETUP.md) - Setup detallado
- [ValidaciÃ³n Portfolio](VALIDACION_PORTFOLIO.md) - Demos para entrevistas
- [Comandos Directos](COMANDOS_DIRECTOS.md) - Referencia rÃ¡pida

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Core ML/Data Science
- **Python** 3.10+ - Lenguaje principal
- **pandas** 2.1+ - ManipulaciÃ³n de datos
- **numpy** 1.26+ - Operaciones numÃ©ricas
- **scikit-learn** 1.3+ - Machine Learning
- **imbalanced-learn** 0.11+ - Manejo de datos desbalanceados
- **pyarrow** 12.0+ - Formato Parquet eficiente

### API & Web
- **FastAPI** 0.104+ - Framework web moderno
- **Uvicorn** 0.24+ - ASGI server
- **Streamlit** 1.25+ - Dashboard interactivo
- **Pydantic** 2.0+ - ValidaciÃ³n de datos
- **python-jose** 3.3+ - JWT tokens
- **passlib** 1.7+ - Hashing de passwords

### Machine Learning Avanzado
- **XGBoost** 2.0+ - Gradient boosting
- **LightGBM** 4.0+ - Gradient boosting eficiente
- **SHAP** 0.42+ - Explicabilidad del modelo

### Testing & Quality
- **pytest** 7.4+ - Framework de testing
- **pytest-cov** 4.1+ - Cobertura de cÃ³digo
- **pytest-mock** 3.10+ - Mocking
- **httpx** 0.25+ - Cliente HTTP async
- **black** 23.7+ - Formateo de cÃ³digo
- **ruff** 0.1+ - Linting

### Infraestructura (opcional)
- **Docker** - ContainerizaciÃ³n local
- **docker-compose** - OrquestaciÃ³n bÃ¡sica
- **Prometheus** - MÃ©tricas
- **Grafana** - VisualizaciÃ³n de mÃ©tricas

### Desarrollo
- **Jupyter** 1.0+ - Notebooks interactivos
- **IPython** 8.0+ - Shell interactivo
- **python-dotenv** 1.0+ - Variables de entorno

---

## ğŸ”„ Workflow de Desarrollo

### 1. Desarrollo de Features

```bash
# 1. Crear rama
git checkout -b feature/nueva-funcionalidad

# 2. Desarrollar
# ... cÃ³digo ...

# 3. Ejecutar tests
pytest -v

# 4. Formatear cÃ³digo
black src/ api/ dashboard/

# 5. Linting
ruff check src/ api/ dashboard/

# 6. Commit
git add .
git commit -m "feat: descripciÃ³n de la feature"

# 7. Push
git push origin feature/nueva-funcionalidad
```

### 2. Docker (opcional)

```bash
# 1. Build de imagen Docker
docker build -t fraud-detection:latest .

# 2. Run local
docker run -p 8000:8000 fraud-detection:latest

# 3. Nota: integraciones cloud se documentan fuera del demo
```

---

## ğŸ—ºï¸ Roadmap

### âœ… Completado (v1.0)

- [x] Pipeline ML end-to-end
- [x] Modelo Random Forest optimizado (95.28% ROC-AUC)
- [x] API REST con autenticaciÃ³n JWT
- [x] Dashboard Streamlit interactivo
- [x] Suite de tests (34/34 pasando)
- [x] DocumentaciÃ³n DVP-PRO completa
- [x] ContainerizaciÃ³n con Docker

### ğŸš§ En Progreso (v1.1)

- [ ] IntegraciÃ³n con MLflow para experiment tracking
- [ ] A/B testing de modelos (entorno de demo)
- [ ] CI/CD pipeline con GitHub Actions
- [ ] Mejoras en el dashboard (mÃ¡s visualizaciones)

### ğŸ“‹ Planificado (v2.0)

- [ ] Modelo ensemble (Random Forest + XGBoost + LightGBM)
- [ ] Feature store con Feast
- [ ] Streaming de datos con Kafka
- [ ] DetecciÃ³n automÃ¡tica de data drift con Evidently
- [ ] API rate limiting y caching con Redis
- [ ] Despliegue multi-cloud (si se requiere)
- [ ] Explainability avanzada con SHAP
- [ ] Retraining automÃ¡tico con Airflow

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### GuÃ­a de ContribuciÃ³n

- Seguir PEP8 para cÃ³digo Python
- AÃ±adir tests para nuevas funcionalidades
- Actualizar documentaciÃ³n segÃºn cambios
- Ejecutar `black` y `ruff` antes de commit

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- Dataset original: [Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- MetodologÃ­a DVP-PRO desarrollada por Ing. Daniel Varela Perez
- Comunidad open-source de scikit-learn, FastAPI y Streamlit

---

## ğŸ“¬ Contacto Profesional

**Ing. Daniel Varela PÃ©rez**
Senior Data Scientist & ML Engineer

ğŸ“§ **Email:** bedaniele0@gmail.com
ğŸ“± **Tel:** +52 55 4189 3428
ğŸ’¼ **LinkedIn:** [Tu perfil LinkedIn]
ğŸ™ **GitHub:** [Tu perfil GitHub]

### Especialidades

- Machine Learning & Deep Learning
- MLOps & ML Systems
- API Development (FastAPI, Flask)
- Data Engineering & Pipelines
- Cloud Architecture (AWS, GCP, Azure)

### Disponibilidad

âœ… Disponible para:
- ConsultorÃ­a en proyectos de ML/AI
- Code review y arquitectura de sistemas
- Training y workshops tÃ©cnicos
- Desarrollo de proyectos end-to-end

---

## ğŸ“Š EstadÃ­sticas del Proyecto

- **LÃ­neas de cÃ³digo:** ~4,700
- **Tests:** 34/34 pasando (100%)
- **Cobertura:** 19%
- **Modelo:** 95.28% ROC-AUC (test set)
- **API endpoints:** 10+
- **Tiempo de response:** <100ms
- **DocumentaciÃ³n:** 8 fases DVP-PRO

---

**Â© 2024 - Ing. Daniel Varela PÃ©rez | MetodologÃ­a DVP-PRO**

*Sistema de DetecciÃ³n de Fraude Financiero - Portfolio Demo*

---

## ğŸ”– Tags

`machine-learning` `fraud-detection` `random-forest` `fastapi` `streamlit` `mlops` `python` `data-science` `dvp-pro` `portfolio-project`
